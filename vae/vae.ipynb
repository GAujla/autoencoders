{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform = transforms.ToTensor()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5), (0.5))\n",
    "])\n",
    "\n",
    "mnist_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_data,\n",
    "                                          batch_size=64,\n",
    "                                          shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class VariationalAutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, h_dim=200, z_dim=20):\n",
    "        super().__init__()\n",
    "        # encoder\n",
    "        self.img_2hid = nn.Linear(input_dim, h_dim)\n",
    "        self.hid_2mu = nn.Linear(h_dim, z_dim)\n",
    "        self.hid_2sigma = nn.Linear(h_dim, z_dim)\n",
    "\n",
    "        # decoder\n",
    "        self.z_2hid = nn.Linear(z_dim, h_dim)\n",
    "        self.hid_2img = nn.Linear(h_dim, input_dim)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = self.relu(self.img_2hid(x))\n",
    "        mu, sigma = self.hid_2mu(h), self.hid_2sigma(h)\n",
    "        return mu, sigma\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = self.relu(self.z_2hid(z))\n",
    "        return torch.sigmoid(self.hid_2img(h))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, sigma = self.encode(x)\n",
    "        epsilon = torch.randn_like(sigma)\n",
    "        z_new = mu + sigma*epsilon\n",
    "        x_reconstructed = self.decode(z_new)\n",
    "        return x_reconstructed, mu, sigma\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    x = torch.randn(4, 28*28)\n",
    "    vae = VariationalAutoEncoder(input_dim=784)\n",
    "    x_reconstructed, mu, sigma = vae(x)\n",
    "    print(x_reconstructed.shape)\n",
    "    print(mu.shape)\n",
    "    print(sigma.shape)\n",
    "    print(summary(vae, input_size=(784,)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reconstructed_images(model, data_loader, device, num_images=8):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, _ in data_loader:\n",
    "            x = x.to(device).view(-1, INPUT_DIM)\n",
    "            x_reconstructed, _, _ = model(x)\n",
    "            break\n",
    "\n",
    "    fig, axes = plt.subplots(2, num_images, figsize=(num_images*2, 4))\n",
    "    for i in range(num_images):\n",
    "        axes[0, i].imshow(x[i].cpu().reshape(28,28), cmap='gray')\n",
    "        axes[0, i].axis('off')\n",
    "        axes[0, i].set_title(\"Original\")\n",
    "        \n",
    "        axes[1, i].imshow(x_reconstructed[i].cpu().reshape(28,28), cmap='gray')\n",
    "        axes[1, i].axis('off')\n",
    "        axes[1, i].set_title(\"Reconstructed\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_images(model, device, num_images=10, z_dim=2):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(num_images, z_dim).to(device)\n",
    "        generated_images = model.decode(z).cpu()\n",
    "\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(num_images * 2, 2))\n",
    "    for i in range(num_images):\n",
    "        axes[i].imshow(generated_images[i].reshape(28, 28), cmap='gray')\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title(f'Sample {i+1}')\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def visualize_latent_space(model, data_loader, device, num_batches=100):\n",
    "    model.eval()\n",
    "    all_mu, all_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (x, labels) in enumerate(data_loader):\n",
    "            if i >= num_batches:\n",
    "                break\n",
    "            x = x.to(device).view(x.shape[0], -1) # flaten data into single vector per image\n",
    "            mu, sigma = model.encode(x)\n",
    "            all_mu.append(mu.cpu().numpy())\n",
    "            all_labels.append(labels.numpy())\n",
    "\n",
    "    all_mu = np.concatenate(all_mu)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    # x dimension y dimension\n",
    "    scatter = plt.scatter(all_mu[:, 0], all_mu[:, 1], c=all_labels, cmap='tab10', alpha=0.7)\n",
    "    plt.colorbar(scatter, ticks=range(10))\n",
    "    plt.xlabel('Latent dimension 1')\n",
    "    plt.ylabel('Latent dimension 2')\n",
    "    plt.title('Latent Space Visualization')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets  # Standard datasets\n",
    "from tqdm import tqdm\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Configuration\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "INPUT_DIM = 784\n",
    "H_DIM = 200\n",
    "Z_DIM = 2\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "LR_RATE = 3e-4  # Karpathy constant\n",
    "\n",
    "# Dataset Loading\n",
    "dataset = datasets.MNIST(root=\"dataset/\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "train_loader = DataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "model = VariationalAutoEncoder(INPUT_DIM, H_DIM, Z_DIM).to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR_RATE)\n",
    "loss_fn = nn.BCELoss(reduction=\"sum\")\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    loop = tqdm(train_loader, desc=f'Epoch [{epoch+1}/{NUM_EPOCHS}]')\n",
    "    for x, _ in loop:\n",
    "        x = x.to(DEVICE).view(x.shape[0], INPUT_DIM)\n",
    "        x_reconstructed, mu, sigma = model(x)\n",
    "        reconstruction_loss = loss_fn(x_reconstructed, x)\n",
    "        kl_div = -torch.sum(1 + torch.log(sigma.pow(2)) - mu.pow(2) - sigma.pow(2))\n",
    "\n",
    "        loss = reconstruction_loss + kl_div\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loop.set_postfix(loss=f'{loss.item()/len(x):.4f}')\n",
    "    \n",
    "    plot_reconstructed_images(model, train_loader, DEVICE)\n",
    "    visualize_latent_space(model, train_loader, DEVICE)\n",
    "    generate_random_images(model, DEVICE, num_images=10, z_dim=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
